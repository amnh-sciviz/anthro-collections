# -*- coding: utf-8 -*-

import argparse
import collections
import glob
import math
import os
from pprint import pprint
import sys

import lib.io_utils as io
import lib.list_utils as lu
import lib.math_utils as mu

# input
parser = argparse.ArgumentParser()
parser.add_argument('-in', dest="INPUT_FILE", default="data/MexicoAndCentralAmerica.csv", help="File generated by html_to_csv.py")
parser.add_argument('-has', dest="FIELDS_HAS", default="Curatorial Notes,Exhibition History,Publication History,Dimensions,Thumb URL", help="List of fields to show presence of value")
parser.add_argument('-counts', dest="FIELDS_COUNTS", default="Acquisition Year,Categories,Collection,Collector,Country,Culture,Date,Donor,Hall,Keywords,Locale,Material,Period,Subject,Technique", help="List of fields to show counts")
parser.add_argument('-lists', dest="FIELDS_LISTS", default="Categories,Keywords", help="List of fields that are comma-separated lists")
parser.add_argument('-merge', dest="FIELDS_MERGE", default="Categories=Category", help="List of fields that are comma-separated lists")
parser.add_argument('-count', dest="DISPLAY_COUNT", default=30, type=int, help="Number to display per group")
parser.add_argument('-out', dest="OUTPUT_FILE", default="reports/MexicoAndCentralAmerica.txt", help="Output text file")
parser.add_argument('-detail', dest="DETAILED_OUTPUT_FILE", default="", help="Output each field as an individual csv file")
a = parser.parse_args()

FIELDS_HAS = a.FIELDS_HAS.strip().split(",")
FIELDS_COUNTS = a.FIELDS_COUNTS.strip().split(",")
FIELDS_LISTS = a.FIELDS_LISTS.strip().split(",")
FIELDS_MERGE = io.parseQueryString(a.FIELDS_MERGE.strip())

# Make sure output dirs exist
io.makeDirectories([a.OUTPUT_FILE])

if len(a.DETAILED_OUTPUT_FILE) > 0:
    io.makeDirectories([a.DETAILED_OUTPUT_FILE])

items = []
fieldNames = []

if "*" in a.INPUT_FILE:
    files = glob.glob(a.INPUT_FILE)
    for fn in files:
        fFieldNames, fItems = io.readCsv(fn)
        fieldNames += fFieldNames
        items += fItems
    fieldNames = lu.unique(fieldNames)

else:
    fieldNames, items = io.readCsv(a.INPUT_FILE)

# make unique based on id
items = list({item['Catalog No']:item for item in items}.values())

itemCount = len(items)

# Parse lists
for i, item in enumerate(items):
    for field in FIELDS_LISTS:
        items[i][field] = [value.strip() for value in item[field].strip().split(",")]

# Merge lists
for i, item in enumerate(items):
    for field in FIELDS_MERGE:
        otherField = FIELDS_MERGE[field]
        values = [item[field]] if isinstance(item[field], str) else item[field]
        otherValues = [item[otherField]] if isinstance(item[otherField], str) else item[otherField]
        values = set(values).union(set(otherValues))
        items[i][field] = list(values)

outputLines = []
outputLines.append("Total item count: %s" % mu.formatNumber(itemCount))

for field in FIELDS_COUNTS:
    values = []
    if field in FIELDS_LISTS:
        values = lu.flattenList([item[field] for item in items if item[field]])
        values = [value for value in values if value != ""]
    else:
        values = [item[field] if field in item and item[field] != "" else "<empty>" for item in items]

    uvalues = list(set(values))

    outputLines.append("\n==============================================================================")
    outputLines.append("Field: %s (%s unique values) / Top %s:" % (field, mu.formatNumber(len(uvalues)), a.DISPLAY_COUNT))
    outputLines.append("------------------------------------------------------------------------------")

    counter = collections.Counter(values)
    counts = counter.most_common(a.DISPLAY_COUNT)
    for value, count in counts:
        outputLines.append("%s (%s%%)\t %s" % (mu.formatNumber(count), round(1.0 * count / itemCount * 100.0, 2), value))

    if len(a.DETAILED_OUTPUT_FILE) > 0:
        filename = a.DETAILED_OUTPUT_FILE % field.replace(" ", "_")
        counts = counter.most_common()
        rows = []
        for value, count in counts:
            rows.append({
                "text": value,
                "count": count,
                # "percent": round(1.0 * count / itemCount, 3)
            })
        io.writeCsv(filename, rows, ["text", "count"])

for field in FIELDS_HAS:
    has = 0
    for item in items:
        if field not in item:
            continue
        value = item[field]
        if isinstance(value, str) and len(value.strip()) > 0 or isinstance(value, list) and len(value) > 0:
            has += 1
    hasnt = itemCount - has
    outputLines.append("\n==============================================================================")
    outputLines.append("FIELD: %s" % field)
    outputLines.append("------------------------------------------------------------------------------")
    outputLines.append("%s (%s%%)\t have" % (mu.formatNumber(has), round(1.0 * has / itemCount * 100, 2)))
    outputLines.append("%s (%s%%)\t don't have" % (mu.formatNumber(hasnt), round(1.0 * hasnt / itemCount * 100, 2)))

outputStr = "\n".join(outputLines) + "\n"
with open(a.OUTPUT_FILE, "w") as f:
    f.write(outputStr)
print("Wrote report to: %s" % a.OUTPUT_FILE)
